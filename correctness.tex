\chapter{Correctness}
\label{chap:correctness}

One of the two fundamental issues in designing algorithms is \textit{correctness}. In this chapter, we will explore techniques to show and prove the correctness of algorithms.

\section{Defining correctness}
Your notion of correctness might be based on your experience writing code in your introductory CS classes, where you think that your code is correct as long as it matches with the sample output given, or as long as your program does not crash or go to an infinite loop.

However for this course, we would like to make a distinction between empirical correctness and provable correctness.

Simply put, we say that an algorithm is \textit{empirically correct} if it produces the correct output for every input that you only tested or practically use. More often than not, your set of inputs is just a proper subset of all the possible inputs, which is not exhaustive enough if you want to assert the correctness of the algorithm. Since you do not tend to use inputs involving edge cases, you will never know how the algorithm behaves when given unexpected inputs.

On the other hand, we say that an algorithm is \textit{provably correct} if it produces the correct output for every possible input. This does not mean you have exhaustively tested the algorithm for each and every possible input, because that is simply impractical to do. Instead, it means that you have a proof that the algorithm returns the correct output for every input.

We can have the following definition of algorithmic correctness:
\begin{definition}{(\cite{cormen_introduction_2009})}
An algorithm is said to be correct if, for every input instance, it halts with the correct output.
\end{definition}

Why should we care whether or not an algorithm is provably correct? From our experience, we design algorithms such that we know they work given reasonable inputs. But the end-users of these algorithms may not give reasonable inputs all the time.

\begin{example}[A crappy analogy, literally, sort of...]
Consider a chocolate fountain. It takes in melted chocolate as input. The manufacturer guarantees that the chocolate fountain will operate and work properly as intended, provided that it only uses melted chocolate.

\begin{figure}[H]
    \centering
    \includegraphics[width=12cm]{figures/Chocolate-Fountains.png}
    \caption{When set up properly, a chocolate fountain can be a perfect party piece}
    % \label{fig:my_label}
\end{figure}

What if the end-user somehow screwed up while operating the chocolate fountain, and a small amount of water made its way through the melted chocolate? Well, it suddenly looks unappetizing... Ew.

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{figures/fountain_fail.png}
    \caption{Instant disaster, just add water! (View the GIF here: \url{https://i.imgur.com/OX7Gg3R.gifv})}
    % \label{fig:my_label}
\end{figure}

It turns out water and melted chocolate don't mix. What basically happened is that the melted chocolate has seized, meaning the chocolate has clumped together to form chunks. As a result, the chocolate fountain cannot efficiently pump out the chocolate as smoothly like it did previously.

In this case, the end-user cannot complain to the manufacturer that the chocolate fountain is defective, just because it cannot pump the seized chocolate. 
\end{example}

When designing algorithms, we want to ensure that every possible inputs are all accounted for, even edge cases, and in the event that the algorithm gets an unexpected input, it should have been dealt with accordingly. We do not want an algorithm to behave unexpectedly or inconsistently when given unexpected input.

By ensuring that an algorithm is provably correct, we avoid unexpected or undefined behavior. Thus, we ensure that an algorithm \textit{expectedly} returns the correct output.

\section{Mathematical induction}
One technique to prove the correctness of an algorithm is through a proof by induction. %This is commonly used when an algorithm only involves a closed-form expression.
You can think of mathematical induction like climbing an infinitely high ladder. We obviously know that we can reach the first rung of the ladder, which is just near the base. If we can reach some rung of the ladder, then we can also reach the next rung. From these two statements, what can we conclude? We can then conclude that we can reach \textit{any} rung of the ladder.

We often prove by induction when an algorithm only involves a closed-form expression. Recall that there is a neat formula to get the sum of integers from $1$ to $n$, which is as follows:
\[
\sum_{i=1}^{n} i = \frac{n\left(n+1\right)}{2}
\]

How are we sure that this formula gives the correct answer for all positive integers $n$? We can do a proof by induction by following these steps:
\begin{enumerate}
    \item Base case: Show that the statement is true for all trivial inputs.
    \item Inductive hypothesis: Assume that the statement is true for some $k$.
    \item Inductive step: Show that the statement is true for $k+1$, which uses the inductive hypothesis.
\end{enumerate}

\begin{claim}
The above formula gives the correct answer for integers $n>0$.
\end{claim}
\begin{proof}
    When $n=1$, the sum of integers from $1$ to $1$ is just $1$, and substituting $n$ with $1$ in the formula, we get $\frac{1\left(1+1\right)}{2} = \frac{1\cdot 2}{2} = 1$. Thus the formula is correct for $n=1$.

    Assume that the sum of integers from $1$ to $k$ is $\frac{k\left(k+1\right)}{2}$, for some integer $k < n$. We now show that the formula also holds for $n = k+1$.

    For the inductive step, we want to show that
\[
    \sum_{i=1}^{k+1} i = \frac{\left(k+1\right) \left(k+2\right)}{2}
\]
holds. Then
    \begin{align*}
        \sum_{i=1}^{k+1} i &= 1 + 2 + \cdots + k + \left(k+1\right) \\
        &= \sum_{i=1}^{k} i + \left(k+1\right) \\
        &= \frac{k\left(k+1\right)}{2} + \left(k+1\right) & \text{(by the inductive hypothesis)} \\
        &= \frac{\left(k^2 + k\right) + \left(2k + 2\right)}{2} \\
        &= \frac{k^2 + 3k + 2}{2} \\
        &= \frac{\left(k+1\right) \left(k+2\right)}{2}
    \end{align*}

    Since we have shown that the formula gives the correct answer for $n = k+1$, therefore it is correct for $n>0$.
\end{proof}

We also use induction to prove the correctness of recursive algorithms.

\begin{example}[Proving correctness using induction, from \cite{skiena_algorithm_2008}]
    Suppose we want to prove that the following recursive algorithm for incrementing an integer is correct:
    \begin{algorithm}[H]
        \caption{Increment an integer}
        \begin{algorithmic}[1]
            \Function{Increment}{$y$}
                \If{$y=0$}
                    \Return $1$
                \Else
                    \If{$y \bmod 2 \ne 0$}
                    \Comment{if $y$ is odd}
                    \Return $2\cdot \text{\Call{Increment}{$\lfloor y/2\rfloor$}}$
                    \Else
                        \Return $y+1$
                    \EndIf
                \EndIf
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    \begin{proof}
        The base case here is when $y=0$. Obviously, $0+1=1$ and the algorithm returns $1$ as expected. So the algorithm is correct for the base case.

        Assume that the algorithm returns the correct answer when $y = n-1$. This is our inductive hypothesis. Now, we need to show that the algorithm also returns the correct answer when $y = n$.

        Recall that we have two cases. First, let us do the inductive step for the case when $y$ is even. We can see that the algorithm explicitly returns $y+1$, which is what we expect.

        For the case when $y$ is odd, it relies on getting the value of \Call{Increment}{$\lfloor y/2 \rfloor$}, which we want to assume is correct by our inductive hypothesis. But there's a slight problem. We only assume that the algorithm is correct for $y = n-1$, but not for $y = n/2$.

        We can fix this by making our inductive hypothesis stronger. Instead of just assuming correctness for a single value (like $n-1$), we can assume correctness for all possible values less than $n-1$. So we now assume that the algorithm returns the correct answer for all $y \le n-1$.

        With this stronger inductive hypothesis, we can now prove for the case when $y$ is odd. Since $y = 2k+1$ for some integer $k$, then we have the following:
        \begin{align*}
            2 \cdot \text{\Call{Increment}{$\lfloor (2k+1)/2\rfloor$}} &= 2 \cdot \text{\Call{Increment}{$\lfloor k+ 1/2\rfloor$}} \\
            &= 2 \cdot \text{\Call{Increment}{$k$}} \\
            &= 2 \cdot (k+1) \\
            &= 2k + 2 \\
            &= y+1
        \end{align*}

        Since we have shown that the algorithm returns the correct answer for both even and odd values of $y$, then we can conclude that the algorithm is correct.
    \end{proof}
\end{example}

As a rule of thumb, if the recursive case reduces the size of the problem by $1$, then it suffices to use ordinary induction. If the recursive case reduces the size of the problem by more than $1$ (e.g., by half the size), then it becomes necessary to use strong induction.

\section{Loop invariants}
How do loops work anyway? Recall that a loop consists of a condition, and a series of statements. These statements are always executed, so long as the loop condition holds true. Once the loop condition does not hold anymore, the loop terminates without executing the statements.

If for each iteration, everything inside the loop gets executed, then there must be some condition that holds true at the start of every iteration. Furthermore, the statements inside the loop must make sure that this condition will still hold at the start of the next iteration. This condition is what we call a \textit{loop invariant}. We use loop invariants to prove the correctness of iterative algorithms.

\begin{definition}
A loop invariant is a statement that remains true before, during, and after every iteration of the loop. It satisfies these properties:
\begin{enumerate}
    \item Initialization: A loop invariant is true at the start of the loop.
    \item Maintenance: If a loop invariant is true at the start of the current iteration, then it should also remain true at the start of the next iteration.
    \item Termination: A loop invariant remains true after the loop ends, which helps us show that the algorithm is correct.
\end{enumerate}
\end{definition}

If we have successfully shown that the loop invariant for an algorithm satisfies those properties, we can use the fact that the loop invariant still holds true upon termination of the loop in order to show that the algorithm is correct.

How do we find a loop invariant? One way is to consider what output we should expect the algorithm to return. Most likely, the variable whose value will be returned at the end of the loop is being changed at every iteration.

\begin{example}[Finding a loop invariant]
    Suppose we have an algorithm for getting the product of integers from $1$ to $n$.
    \begin{algorithm}[H]
        \caption{Get the product of integers from $1$ to $n$ }
        \begin{algorithmic}[1]
            \Require An integer $n$, where $n>0$ 
            \Ensure The product of integers from $1$ to $n$ 
            \Function{IntProd}{$n$}
            \State $P \gets 1$
            \For{$k \gets 2$ to  $n$}
            \State $P \gets P \cdot k$ 
            \EndFor
            \Return $P$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    Notice that inside the for loop, the value of $P$ is updated. For each iteration, what does the value of $P$ represent? 

    At the start of the first iteration, the value of $P$ is $1$. Then at the start of the second iteration, the value of $P$ is now $2$, since we have reassigned $P$ with the value of $P$ at that time, multiplied with the previous value of $k$ which is $2$. 

    Then at the start of the third iteration, the value of $P$ is now $6$. In fact, we can generalize this further for any given iteration. We can say that at the start of the $i$th iteration, the value of $P$ is $1 \cdot 2 \cdot \cdots \cdot \left(k-1\right)$. Notice that this statement holds true at the start of every iteration of the for loop. We now have a loop invariant for this algorithm.

    In simpler terms, the loop invariant states that at the start of the $i$th iteration, the value of $P$ contains the product of integers from $1$ to $k-1$.
\end{example}

Another way is to consider what happens in each iteration of the loop. Try looking at how the value of the variables change throughout an iteration.

\begin{example}[Finding a loop invariant]
    Consider an algorithm that uses binary search to find some element $e$ within a sorted array $A$, given that $e$ is an element in the array. Once found, it will return the target element's index within $A$.

    \begin{algorithm}[H]
        \caption{Get the index of an element in a sorted array}
        \begin{algorithmic}[1]
            \Require A sorted array $A$ of $n$ elements and the target element $e$
            \Ensure The index of $e$ in the array
            \Function{SearchElement}{$A$, $e$}
                \State $L \gets 1$
                \State $R \gets n$
                \While{$L \le R$}
                    \State $M \gets \lfloor\frac{L+R}{2}\rfloor$
                    \If{$A[M] = e$}
                        \Return $M$
                    \ElsIf{$A[M] > e$}
                        \State $R \gets M-1$
                    \Else
                        \State $L \gets M+1$
                    \EndIf
                \EndWhile
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    At first glance, we can see that the variables $L$, $R$, and $M$ are updated in each iteration. But we are not yet sure how these variables get updated, so let us simulate what happens in the algorithm with a sample input.
    Suppose we have a sorted array $A$ with elements $\List{-5, 10, 14, 33, 42, 42, 42}$, and we want to find the index of the element $14$ within the array.

    At the start of the first iteration, we have $L = 1$ and $R = 7$ (since there are $n=7$ elements in the given array). As we go through the first iteration, the value of $M$ gets updated to $\lfloor\frac{1+7}{2}\rfloor = 4$. Then we compare the value of $A[4]$ (which is $33$) and the target element $e = 14$. Since $A[4]>14$, we update the value of $R$ to $4-1 = 3$.

    At the start of the second iteration, we have $L = 1$ and $R = 3$. The value of $M$ gets updated to $\lfloor\frac{1+3}{2}\rfloor = 2$. Since $A[2] = 10$ is less than $14$, we update the value of $L$ to $2+1 = 3$.

    At the start of the third iteration, we have $L=3$ and $R=3$. The value of $M$ gets updated to $\lfloor\frac{3+3}{2}\rfloor = 3$. Since $A[3] = 14$ is equal to the target element $14$, then the algorithm returns $3$, the index of $14$, and the algorithm terminates.

    What have you noticed? It's easy to observe that the value of $L$ increases or the value of $R$ decreases in every iteration. We could call this a loop invariant, but it would not help us in proving the correctness of the algorithm.

    Maybe we're on to something when we mentioned about the changes in $L$ and $R$. You can also observe that $L$ and $R$ tend to converge towards a single value, which would be the index of the element. This implies that $L$ and $R$ enclose the location of the target element, which is always true at the start of every iteration. This is our loop invariant!

    In other words, the loop invariant for this algorithm states that at the start of each iteration in the while loop, the subarray $\List{A[L], \ldots, A[R]}$ contains the target element $e$.
\end{example}

We can also consider how the algorithm ``builds up'' the answer. This is somewhat related to the previous method of considering what the algorithm is expected to output. Try looking at how it builds up a partial solution at every iteration, so at the end of the loop the answer would now correspond for the entire solution.

\begin{example}[Finding a loop invariant]
    This is an algorithm that merge sort uses in its merging step.
    \begin{algorithm}[H]
        \caption{Merge two sorted arrays together}
        \begin{algorithmic}[1]
            \Require Two sorted arrays $L$ and $R$
            \Ensure A single sorted array $S$
            \Function{Merge}{$L$, $R$}
                \State $p \gets \text{\Call{Length}{$L$}}$
                \State $q \gets \text{\Call{Length}{$R$}}$
                \State $n \gets p + q$
                \State $S \gets \text{empty array of size $n$}$
                \State $i \gets 1$
                \Comment{pointer for $L$}
                \State $j \gets 1$
                \Comment{pointer for $R$}
                \State $L[p+1] \gets \infty$
                \State $R[q+1] \gets \infty$
                \For{$k \gets 1$ to $n$}
                    \If{$L[i] \le R[j]$}
                        \State $S[k] \gets L[i]$
                        \State $i \gets i+1$
                    \Else
                        \State $S[k] \gets R[j]$
                        \State $j \gets j+1$
                    \EndIf
                \EndFor
                \Return $S$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    Inside the for loop, the variables $i$ and $j$ are modified, as well as the array $S$. %It often helps if you try simulating what happens in the algorithm by using a sample input. For example, suppose we have two sorted arrays $L$ with elements $\List{1,4}$, and $R$ with elements $\List{2,3,5}$.

    Notice that the goal of the for loop is to assign a value for each position in the new array $S$, that's why the loop runs from $1$ to $n$, which corresponds to the length of $S$. 

    The variables $i$ and $j$ are pointers for $L$ and $R$, respectively. They both refer to the index of the smallest element in the respective arrays that is not in array $S$ yet. How can we be sure about this? If $L[i]$, for example, gets added to $S$, then $i$ would get incremented, so it would now point to the next smallest element in $L$ and for sure that element isn't on $S$ yet. We can also say the same thing about $R[j]$ and its pointer $j$.

    % At the start of the first iteration, what can we say about $S$? It's still empty because at this point, we haven't yet modified the array after the initialization. 

    The loop invariant states that at the start of each iteration $k$, the non-empty part of $S$ contains the $k-1$ smallest elements of $L$ and $R$ in sorted order.
\end{example}

Now that you have established a loop invariant, the difficult part is done. Now we need to show that our chosen loop invariant satisfies the initialization, maintenance, and termination properties. You may notice that by showing that those properties are satisfied, the resulting proof of correctness will resemble a proof by induction!

The termination property says that the loop invariant remains true after the loop ends. In other words, we conclude that after the last iteration of the loop, the algorithm returns the expected output, so it must be correct. You may imply from the name itself that the termination property must show that the loop (and thus the algorithm) terminates. It is obvious that a for loop always terminates, but you can't say the same for while loops. Somehow you must prove that the loop terminates, otherwise the proof won't work. But proving that the loop indeed terminates is already implied when we analyze the running time of the algorithm.

If we want to show that our loop invariant is true at the end of the loop, then we need to show that it is also true at the start of the loop. The initialization property says that the loop invariant is true at the start of the loop. You could think of this as showing that the algorithm is correct for the base case.

The maintenance property is like the inductive step in a proof by induction. You assume that the loop invariant holds true at the start of some iteration. Then you need to show that it still holds true at the start of the next iteration.

\begin{example}[Proving the correctness of \textsc{IntProd}]
    Our loop invariant for the \textsc{IntProd} algorithm states that at the start of the $i$th iteration, the value of $P$ contains the product of integers from $1$ to $k-1$.

    \begin{proof}
        We show that our chosen loop invariant satisfies the initialization, maintenance, and termination properties.

    \begin{enumerate}
        \item Initialization: At the start of the first iteration, we have $k=2$. By the loop invariant, the value of $P$ contains the product of integers from $1$ to $2-1=1$ which is just $1$, and this is what $P$ has been set to.

        \item Maintenance: Assume that at the start of some iteration, the loop invariant holds true, so we have $k = j$ for some $j$. By the loop invariant, the value of $P$ contains the product of integers from $1$ to $j-1$. Then we multiply $P$ by $j$, so the value of $P$ is now the product of integers from $1$ to $j$. Thus the loop invariant still holds true for the next iteration where $k= j+1$.

        \item Termination: At the end of the for loop, we have $k = n+1$. By the loop invariant, the value of $P$ contains the product of integers from $1$ to $n$. This is what the algorithm should return, and which it then returns.
    \end{enumerate}

    Therefore, the \textsc{IntProd} algorithm is correct.
    \end{proof}
\end{example}

\begin{example}[Proving the correctness of \textsc{SearchElement}]
    Our loop invariant of the \textsc{SearchElement} algorithm states that at the start of each iteration in the while loop, the subarray $\List{A[L],\ldots,A[R]}$ contains the target element $e$.

    \begin{proof}
        We show that our chosen loop invariant satisfies the initialization, maintenance, and termination properties.

        \begin{enumerate}
            \item Initialization: At the start of the first iteration, we have $L=1$ and $R=n$. By the loop invariant, the subarray $\List{A[1],\ldots,A[n]}$ contains $e$, which is obviously true since the subarray is essentially the whole array itself and $e$ is an element of the array.
            \item Maintenance: Assume that at the start of some iteration, the loop invariant holds true, so we have $L=\ell$ and $R = r$. By the loop invariant, the subarray $\List{A[\ell],\ldots,A[r]}$ contains $e$, so we can also say that $A[\ell] \le e$ and $e \le A[r]$. The value of $M$ gets updated to $\lfloor\frac{\ell+r}{2}\rfloor$. This implies that $A[\ell] \le A[M] \le A[r]$. 
                
                There are two possible cases, either $A[M] > e$ or $A[M] < e$. If $A[M] > e$, then we know that the target element is smaller than the middle element of the subarray, so the value of $R$ gets updated to $M-1$. Since $A[\ell] \le e$ and $A[M-1] \le A[M]$, then the condition $A[\ell] \le e \le A[M-1]$ holds true. Thus the subarray $\List{A[\ell],\ldots,A[M-1]}$ contains $e$, so the loop invariant is preserved for the start of the next iteration.

                If $A[M] < e$, then we know that the target element is larger than the middle element of the subarray, so the value of $L$ gets updated to $M-1$. Since $e \le A[r]$ and $A[M] \le A[M+1]$, the condition $A[M+1] \le e \le A[r]$ holds true. Thus the subarray $\List{A[M+1],\ldots,A[r]}$ contains $e$, so the loop invariant is still preserved for the start of the next iteration.

            \item Termination: Notice that the while loop terminates when it returns a value, which happens when $A[M]$ is equal to the target element $e$. 

                At the end of the last iteration, we have $L = R = k$ for some index $k$. Then the value of $M$ was updated to $\lfloor\frac{2k}{2}\rfloor = k$. By the loop invariant, the subarray $\List{A[k],\ldots,A[k]}$ contains $e$. But the subarray is just a single element containing $A[k]$, so this must be the target element itself, since $A[k] = e = A[k]$. Thus the algorithm returns $k$, the index of the target element, which is what we expect the algorithm to return.
        \end{enumerate}

        Therefore, the \textsc{SearchElement} algorithm is correct.
    \end{proof}
\end{example}

There may be cases when an algorithm involves multiple loops. For nested loops, we work inside-out by establishing a loop invariant for the inner loop and show that it satisfies the termination property. Then we use that loop invariant to formulate another loop invariant for the outer loop and also show that it satisfies the termination property.

\begin{example}[Finding loop invariants in nested loops]
    The Cartesian product\footnote{If you're familiar with SQL, you can get the Cartesian product by doing a cross join from two tables.} is an operation where given two sets $A$ and $B$, returns the product $A \times B$ which is the set of all ordered pairs $\left(a, b\right)$ where $a \in A$ and $b \in B$. In set-builder notation,
    \[
        A \times B = \List{\left(a,b\right) \mid a \in A \text{ and } b \in B}.
    \]
    For example, if $A = \List{1,3}$ and $B = \List{2,4,6}$, then 
    \[
        A \times B = \List{(1,2),(1,4),(1,6),(3,2),(3,4),(3,6)}.
    \]
    The following iterative algorithm gets the Cartesian product of two arrays $A$ and $B$.
    \begin{algorithm}[H]
        \caption{Get the Cartesian product of two arrays}
        \begin{algorithmic}[1]
            \Require Two arrays $A$ (of size $n$) and $B$ (of size $m$)
            \Ensure The Cartesian product $A \times B$
            \Function{CrossJoin}{$A$, $B$}
                \State $P \gets \text{empty array of size $nm$}$
                \State $k \gets 1$
                \For{$i \gets 1$ to $n$}
                    \For{$j \gets 1$ to $m$}
                        % \State \Call{Append}{$P$, $\left(A[i], B[j]\right)$}
                        % \Comment{$\left(A[i], B[j]\right)$ is an ordered pair}
                        \State $C[k] \gets \left(A[i], B[j]\right)$
                        \State $k \gets k+1$
                    \EndFor
                \EndFor
                \Return $P$
           \EndFunction
       \end{algorithmic}
   \end{algorithm}

   We have two for loops that are nested, so we need to find a loop invariant for each. 

   Let us first establish a loop invariant for the inner loop (lines 5--7). Since the inner loop iterates through each element of $B$, then we can say the elements of the Cartesian product $\List{A[i]} \times \List{B[1],\ldots,B[j-1]}$ have been added to $P$ at the start of each iteration.

   To establish a loop invariant for the outer loop (lines 4--7), we can use the termination property of the loop invariant for the inner loop. Recall that when the inner loop terminates, the invariant states that the elements of the Cartesian product $\List{A[i]} \times B$ have been added to $P$. So at the start of each iteration in the outer loop, we can say that the non-empty part of $P$ contains the elements of $\List{A[1],\ldots,A[i-1]} \times B$.

   Then by the end of the outer loop, $P$ contains the elements of $A \times B$, which is what we want the algorithm to return.

   We have found the two loop invariants in the algorithm, which are as follows:
   \begin{itemize}
       \item Inner loop: At the start of each iteration $j$, the elements of the Cartesian product $\List{A[i]} \times \List{B[1],\ldots,B[j-1]}$ have been added to $P$.

       \item Outer loop: At the start of each iteration $i$, the non-empty part of $P$ contains the elements of the Cartesian product $\List{A[1],\ldots,A[i-1]} \times B$.
   \end{itemize}
\end{example}

\begin{exercises}
    \begin{enumerate}
        \item Induction warmup! Prove the following statements using induction.
            \begin{enumerate}
                \item $\displaystyle\sum_{i=1}^n i^2 = \frac{n\left(n+1\right)\left(2n+1\right)}{6}$
                \item $\displaystyle\sum_{i=1}^n i^3 = \frac{n^2 \left(n+1\right)^2}{4}$
                \item $1 + 2 + 4 + \cdots + 2^{n-1} = 2^n - 1$
                \item $1 + 4 + 16 + \cdots + 4^{n-1} = \frac{1}{3} \left(4^n - 1\right)$
                \item $n < 2^n$ for any positive integer $n$
                \item $\left(n+1\right)^n < n^{n+1}$ for any integer $n \ge 3$
                \item $n! > n^2$ for $n \ge 4$
                \item $n! > \left(n/2\right)^{n/2}$
                \item $2n+1 < n^2$ for $n \ge 3$
                \item $3^n \ge 3n$
                \item $3^n > 2^n + 10n$ for $n \ge 4$
            \end{enumerate}
        
        \item [\challenge] We can define the nonnegative powers of a number $x$ by the rules $x^0 = 1$ and $x^{n+1} = x^n \cdot x$. Explain why this defines $a^n$ for all integers $n \ge 0$. From this definition, prove that $x^m \cdot x^n = x^{m+n}$ for integers $m \ge 0$ and $n \ge 0$.

        \item Consider this algorithm to find the minimum element in an array.
            \begin{algorithm}[H]
                \caption{Get the minimum element in the array}
                \begin{algorithmic}[1]
                    \Require An array $A$ of $n$ integers, where $n>0$
                    \Ensure The minimum element in $A$
                    \Function{ArrayMin}{$A$}
                        \State $m \gets A[1]$
                        \For{$i \gets 2$ to $n$}
                            \If{$m > A[i]$}
                                \State $m \gets A[i]$
                            \EndIf
                        \EndFor
                        \Return $m$
                    \EndFunction
                \end{algorithmic}
            \end{algorithm}
        \begin{enumerate}
            \item State the loop invariant in the algorithm.
            \item Show that your chosen loop invariant satisfies the initialization, maintenance, and termination properties.
        \end{enumerate}

        \item Luis has designed an in-place\footnote{We say that an algorithm is \textit{in-place} if it does not consume any additional space. We will encounter this term again when we talk about sorting algorithms.} algorithm to reverse an array. 
            \begin{algorithm}[H]
                \caption{Reverse an array}
                \begin{algorithmic}[1]
                    \Require An array $A$ of $n$ elements
                    \Ensure The array in reverse
                    \Function{Yarra}{$A$}
                        \State $i \gets \lfloor \left(n-1\right)/2 \rfloor$
                        \State $j \gets \lfloor n/2 \rfloor$
                        \While{$i \ge 1$ and $j \le n$}
                            \State \Call{Swap}{$A[i]$, $A[j]$}
                            \State $i \gets i-1$
                            \State $j \gets j+1$
                        \EndWhile
                        \Return $A$
                    \EndFunction
                \end{algorithmic}
           \end{algorithm}

        \begin{enumerate}
            \item State the loop invariant in the algorithm.
            \item Show that your chosen loop invariant satisfies the initialization, maintenance, and termination properties.
        \end{enumerate}

        \item While debugging a legacy app created in the early 2000s, you have come across this mysterious algorithm that was left undocumented (as was the standard procedure at that time) involving a for loop.
            \begin{algorithm}[H]
                \caption{A mysterious algorithm that does... something}
                \begin{algorithmic}[1]
                    \Require Two arrays $A$ and $B$
                    \Ensure An array
                    \Function{Mystery}{$A$, $B$}
                        \State $C \gets \text{empty array}$
                        \ForEach{element $a$ in $A$}
                            \If{$a$ in $B$}
                                \State \Call{Append}{$C$, $a$}
                            \EndIf
                        \EndFor
                        \Return $C$
                    \EndFunction
                \end{algorithmic}
            \end{algorithm}
            
        \begin{enumerate}
            \item What does the \textsc{Mystery} algorithm output?
            \item State the loop invariant in the algorithm.
            \item Show that your chosen loop invariant satisfies the initialization, maintenance, and termination properties.
        \end{enumerate}
                        
        \item There is an efficient method to evaluate a polynomial $p\left(x\right)$ for some value of $x$, called the Horner's method. Given a polynomial
            \[
                p\left(x\right) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots + a_n x^n
            \]
        we can rewrite this in terms of only additions and multiplications, such that
        \[
            p\left(x\right) = a_0 + x\cdot\left(a_1 + x\cdot\left(a_2 + \cdots + x\cdot\left(a_{n-1} + x\cdot a_n\right)\right)\right)
        \]
        Here's an algorithm that evaluates a given polynomial at some value of $x$ using the Horner's method. The polynomial is represented as a (zero-indexed) array of $n+1$ coefficients, where $P[i] = a_i$.
        \begin{algorithm}[H]
            \caption{Evaluate a polynomial at a specified value}
            \begin{algorithmic}[1]
                \Require An array of coefficients $P$, where $P = \List{a_0, a_1, a_2, \ldots, a_n}$
                \Ensure The value of the polynomial at $x$
                \Function{PolyEval}{$P$, $x$}
                    \State $y \gets P[n]$
                    \For{$i \gets n-1$ downto $0$}
                        \State $y \gets P[i] + x\cdot y$
                    \EndFor
                    \Return $y$
                \EndFunction
            \end{algorithmic}
        \end{algorithm}

        \begin{enumerate}
            \item State the loop invariant in the algorithm.
            \item Show that your chosen loop invariant satisfies the initialization, maintenance, and termination properties.
        \end{enumerate}

    \item[\challenge] The greatest common divisor (gcd) of two integers is the largest integer that divides them both. For example, the gcd of $6$ and $15$ is $3$, since $3$ divides both $6$ and $15$.

        An efficient algorithm to calculate the gcd of two integers is the Euclidean algorithm (named after Euclid), which is one of the oldest algorithms still in common use today! 

        \begin{algorithm}[H]
            \caption{Calculate the gcd of two numbers}
            \begin{algorithmic}[1]
                \Require Two positive integers $a$ and $b$
                \Ensure The value of $\gcd\left(a, b\right)$
                \Function{Euclid}{$a$, $b$}
                    \State $x \gets a$
                    \State $y \gets b$
                    \While{$y \ne 0$}
                        \State $r \gets x \bmod y$
                        \Comment{the remainder when $x$ is divided by $y$}
                        \State $x \gets y$
                        \State $y \gets r$
                    \EndWhile
                    \Return $x$
                \EndFunction
            \end{algorithmic}
        \end{algorithm}

        \begin{enumerate}
            \item State the loop invariant in the algorithm.
            \item Show that your chosen loop invariant satisfies the initialization, maintenance, and termination properties.
        \end{enumerate}

    \item[\challenge] Here is a straightforward algorithm to multiply two matrices $A$ (of size $m \times n$) and $B$ (of size $n \times p$).
        \begin{algorithm}[H]
            \caption{Multiply two matrices}
            \begin{algorithmic}[1]
                \Require Two matrices $A$ (of size $m \times n$) and $B$ (of size $n \times p$)
                \Ensure A matrix of size $m \times p$
                \Function{MatrixMultiply}{$A$, $B$}
                    \State $C \gets \text{empty array of size $m \times p$}$
                    \For{$i \gets 1$ to $m$}
                        \For{$j \gets 1$ to $p$}
                            \State $C[i][j] \gets 0$
                            \For{$k \gets 1$ to $n$}
                                \State $C[i][j] \gets C[i][j] + A[i][k]\cdot B[k][j]$
                            \EndFor
                        \EndFor
                    \EndFor
                    \Return $C$
                \EndFunction
            \end{algorithmic}
        \end{algorithm}

        \begin{enumerate}
            \item State the loop invariants in the algorithm.
            \item Show that your chosen loop invariants each satisfy the initialization, maintenance, and termination properties.
        \end{enumerate}

    \item[\challenge] Prove that the \textsc{Merge} algorithm is correct by showing that its loop invariant (as established earlier) satisfies the initialization, maintenance, and termination properties.

    \item Here is a recursive algorithm to get the $n$th even number, where $0$ is the first even number.
    \begin{algorithm}[H]
        \caption{Get the $n$th even number}
        \begin{algorithmic}[1]
            \Require An integer $n$, where $n>0$
            \Ensure The $n$th even number
            \Function{Even}{$n$}
                \If{$n=1$}
                    \Return $0$
                \Else
                    \Return $\text{\Call{Even}{$n-1$}} + 2$
                \EndIf
            \EndFunction
        \end{algorithmic}
    \end{algorithm}
        Using induction, prove that the \textsc{Even} algorithm returns the correct answer, using the following steps:
        \begin{enumerate}
            \item Identify the base cases and show that the algorithm returns the correct answer for those cases.
            \item State the inductive hypothesis for the algorithm.
            \item Show that the algorithm also returns the correct answer for the recursive case using your inductive hypothesis.
        \end{enumerate}

        \item[\challenge] Consider this recursive implementation of the merge algorithm.
        \begin{algorithm}[H]
            \caption{Merge two sorted arrays together}
            \begin{algorithmic}[1]
                \Require Two sorted arrays $L$ and $R$
                \Ensure A single sorted array $S$
                \Function{Merge}{$L$, $R$}
                    \If{$L$ is empty}
                        \Return $R$
                    \ElsIf{$R$ is empty}
                        \Return $L$
                    \EndIf
                    \If{$\text{\Call{First}{$L$}} \le \text{\Call{First}{$R$}}$}
                        \Return \Call{Cons}{\Call{First}{$L$}, \Call{Merge}{\Call{Rest}{$L$}, $R$}}
                    \Else
                        \Return \Call{Cons}{\Call{First}{$R$}, \Call{Merge}{$L$, \Call{Rest}{$R$}}}
                    \EndIf
                \EndFunction
            \end{algorithmic}
        \end{algorithm}

        Using induction, prove that the \textsc{Merge} algorithm returns the correct answer, using the following steps:
        \begin{enumerate}
            \item Identify the base cases and show that the algorithm returns the correct answer for those cases.
            \item State the inductive hypothesis for the algorithm.
            \item Show that the algorithm also returns the correct answer for the recursive case using your inductive hypothesis.
        \end{enumerate}

    \end{enumerate}
\end{exercises}
